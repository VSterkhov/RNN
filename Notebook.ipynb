{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a974685f-6b2a-4215-82cd-9f377580afbf",
   "metadata": {},
   "source": [
    "Инициализируем импорт и дату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1211d86-2ee6-4942-a40f-35f8a41750c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\vladislav.sterkhov\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\vladislav.sterkhov\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import keras.layers as L\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])\n",
    "\n",
    "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)\n",
    "\n",
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "from collections import defaultdict\n",
    "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}\n",
    "\n",
    "\n",
    "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines), max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix\n",
    "\n",
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0,len(indices)-1,batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_words,batch_tags = [],[]\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
    "            yield batch_words,batch_tags_1hot\n",
    "        \n",
    "        \n",
    "        \n",
    "def compute_test_accuracy(model):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator)/denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bec60-1e36-468d-8a3a-62ec3eba8c8e",
   "metadata": {},
   "source": [
    "Создадим модель с двунаправленным LSTM слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443e6a77-e452-4b10-8ee5-a931025c8c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          640128    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 100)         49800     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 28)         12880     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 14)          406       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 703,214\n",
      "Trainable params: 703,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(L.Embedding(input_dim=len(all_words), output_dim=64))\n",
    "# Выходом GRU будет 3D тензор размера (batch_size, timesteps, 256)\n",
    "model.add(L.GRU(100, input_shape=(32,58,14),return_sequences=True))\n",
    "# Выходом SimpleRNN будет 2D тензор размера (batch_size, 128)\n",
    "model.add(L.Bidirectional(L.LSTM(14, input_shape=(32,58,14), return_sequences=True)))\n",
    "model.add(L.Dense(len(all_tags),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc10a9-97dd-4a14-98e6-8245496b27cb",
   "metadata": {},
   "source": [
    "Обучим модель и вычислим точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea6c829-dab5-49bc-aa0b-e79a9fc4cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2986\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 13s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.94719\n",
      "\n",
      "1343/1343 [==============================] - 76s 53ms/step - loss: 0.2986\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 13s 28ms/step\n",
      "\n",
      "Validation accuracy: 0.95590\n",
      "\n",
      "1343/1343 [==============================] - 72s 54ms/step - loss: 0.0548\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0450\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 13s 28ms/step\n",
      "\n",
      "Validation accuracy: 0.95953\n",
      "\n",
      "1343/1343 [==============================] - 70s 52ms/step - loss: 0.0450\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0397\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.96199\n",
      "\n",
      "1343/1343 [==============================] - 71s 53ms/step - loss: 0.0397\n",
      "Epoch 5/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0358\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 28ms/step\n",
      "\n",
      "Validation accuracy: 0.96338\n",
      "\n",
      "1343/1343 [==============================] - 74s 55ms/step - loss: 0.0358\n",
      "448/448 [==============================] - 12s 28ms/step\n",
      "\n",
      "Final accuracy: 0.96338\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)\n",
    "\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafba9ac-b5c5-4260-ba6d-a9761ab82cbe",
   "metadata": {},
   "source": [
    "Получаем удачное прохождение теста в 96%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
